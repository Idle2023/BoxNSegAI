{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3FXVrvLUL6d",
        "outputId": "60ca4d74-8a02-4d7b-81a1-f6c84c4ff8b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmB-FJ0tYpAH",
        "outputId": "283252ee-2460-49e4-9701-3ca2f78902e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (6.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip -q install -U ultralytics\n",
        "!pip install pyyaml"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5.git\n",
        "import sys\n",
        "sys.path.append('/content/yolov5/')\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "!wget https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5l6.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPD1yxIWgdzE",
        "outputId": "93aecb15-d8ed-4ab3-c402-338727900e9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'yolov5' already exists and is not an empty directory.\n",
            "--2023-08-25 11:47:44--  https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5l6.pt\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/264818686/fbe2b984-78c2-4dab-8d9d-65d536b96aa8?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230825%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230825T114744Z&X-Amz-Expires=300&X-Amz-Signature=163cbbbbe91b5f10e28b3c986329b07c1b5c1fb0e54d75c261ec03bf0f3476a7&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=264818686&response-content-disposition=attachment%3B%20filename%3Dyolov5l6.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-08-25 11:47:44--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/264818686/fbe2b984-78c2-4dab-8d9d-65d536b96aa8?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230825%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230825T114744Z&X-Amz-Expires=300&X-Amz-Signature=163cbbbbe91b5f10e28b3c986329b07c1b5c1fb0e54d75c261ec03bf0f3476a7&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=264818686&response-content-disposition=attachment%3B%20filename%3Dyolov5l6.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 154521589 (147M) [application/octet-stream]\n",
            "Saving to: ‘yolov5l6.pt’\n",
            "\n",
            "yolov5l6.pt         100%[===================>] 147.36M   181MB/s    in 0.8s    \n",
            "\n",
            "2023-08-25 11:47:45 (181 MB/s) - ‘yolov5l6.pt’ saved [154521589/154521589]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "with open(\"yolov5/models/yolov5l.yaml\", 'r') as file:\n",
        "    config = yaml.load(file, Loader=yaml.FullLoader)\n",
        "config['nc'] = 10\n",
        "with open(\"yolov5/models/yolov5l.yaml\", 'w') as file:\n",
        "    yaml.dump(config, file)"
      ],
      "metadata": {
        "id": "cQWWP_X2h-sa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "import torch\n",
        "from models.yolo import DetectionModel, Detect\n",
        "from utils.general import intersect_dicts\n",
        "import torch.nn as nn\n",
        "\n",
        "model = DetectionModel(cfg='yolov5/models/yolov5l.yaml', nc=10)\n",
        "pretrained_weights = torch.load('yolov5l6.pt')\n",
        "model_dict = model.state_dict()\n",
        "pretrained_dict = {k: v for k, v in pretrained_weights.items() if k in model_dict and model_dict[k].shape == v.shape}\n",
        "model_dict.update(pretrained_dict)\n",
        "model.load_state_dict(model_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEAmthwUgTdF",
        "outputId": "0b329247-b6dc-4d7d-ff31-03869d60b895"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     80775  models.yolo.Detect                      [10, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
            "YOLOv5l summary: 368 layers, 46186759 parameters, 46186759 gradients\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "img_path = '/content/drive/MyDrive/data/2DBBs/training/images/AGS_DA_00C_BA_22090202_000471.jpg'\n",
        "transform = transforms.Compose([\n",
        "            transforms.Pad((0, 420)),\n",
        "            transforms.Resize((640, 640)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.45969197, 0.44145255, 0.45046159],\n",
        "                                 std=[0.27247444, 0.27013482, 0.27866579])\n",
        "        ])\n",
        "original_image = Image.open(img_path)\n",
        "image = transform(original_image)\n",
        "image = image.unsqueeze(0)\n",
        "\n",
        "model.train()\n",
        "output_train = model(image)\n",
        "print(f'image shape: {image.shape}')\n",
        "print('train mode')\n",
        "print(f'output type: {type(output_train)}, len: {len(output_train)}')\n",
        "print(output_train[0].shape, output_train[1].shape, output_train[2].shape)\n",
        "\n",
        "model.eval()\n",
        "output_eval = model(image)\n",
        "print('eval mode')\n",
        "print(f'output type: {type(output_eval)}, len: {len(output_eval)}')\n",
        "print(output_eval[0].shape)\n",
        "print(f'output type: {type(output_eval[1])}, len: {len(output_eval[1])}')\n",
        "print(output_eval[1][0].shape, output_eval[1][1].shape, output_eval[1][2].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjDZtad2jRKX",
        "outputId": "031c10ed-910c-4ce2-da36-8133228a74c0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image shape: torch.Size([1, 3, 640, 640])\n",
            "train mode\n",
            "output type: <class 'list'>, len: 3\n",
            "torch.Size([1, 3, 80, 80, 15]) torch.Size([1, 3, 40, 40, 15]) torch.Size([1, 3, 20, 20, 15])\n",
            "eval mode\n",
            "output type: <class 'tuple'>, len: 2\n",
            "torch.Size([1, 25200, 15])\n",
            "output type: <class 'list'>, len: 3\n",
            "torch.Size([1, 3, 80, 80, 15]) torch.Size([1, 3, 40, 40, 15]) torch.Size([1, 3, 20, 20, 15])\n"
          ]
        }
      ]
    }
  ]
}