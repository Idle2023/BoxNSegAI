{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyONUJJzFDa7AlSm0ZvAXtZh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeongin7103/BoxNSegAI/blob/main/2DBB/%EA%B9%80%EC%A0%95%EC%9D%B8/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXO1ZiUa13-6",
        "outputId": "8d3f5259-7805-4dd5-aeb7-f7cd9146dea5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks/2dbb_ji')"
      ],
      "metadata": {
        "id": "2YH0irG72I15"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim\n",
        "from model import SSD300, MultiBoxLoss\n",
        "import torch.utils.data\n",
        "from utils import *\n",
        "from datasets import CustomDataset\n",
        "\n",
        "global start_epoch, label_map, epoch, checkpoint, decay_lr_at\n",
        "\n",
        "# Data parameters\n",
        "data_folder = '/content/drive/MyDrive/Colab Notebooks/2dbb_ji/'"
      ],
      "metadata": {
        "id": "Wbz1UX1h2JEa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model parameters\n",
        "n_classes = len(label_map)\n",
        "print(n_classes)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "# Learning parameters\n",
        "checkpoint = None  # train mode on/off\n",
        "batch_size = 4\n",
        "iterations = 3\n",
        "# workers = 4\n",
        "print_freq = 100\n",
        "lr = 1e-3\n",
        "decay_lr_at = [80000, 100000]\n",
        "decay_lr_to = 0.1  # decay learning rate to this fraction of the existing learning rate\n",
        "momentum = 0.9  # momentum\n",
        "weight_decay = 5e-4  # weight decay\n",
        "grad_clip = None\n",
        "cudnn.benchmark = True"
      ],
      "metadata": {
        "id": "hOeJVZ772lIw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "156cf9b2-8e32-4d69-9e52-cf6d560d4d38"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11\n",
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_loader, model, criterion, optimizer, epoch):\n",
        "    model.train()  # training mode enables dropout\n",
        "\n",
        "    batch_time = AverageMeter()  # forward prop. + back prop. time\n",
        "    data_time = AverageMeter()  # data loading time\n",
        "    losses = AverageMeter()  # loss\n",
        "\n",
        "    start = time.time()\n",
        "\n",
        "    # Batches\n",
        "    for i, (images, boxes, labels) in enumerate(train_loader):\n",
        "        # images: (N, 3, 300, 300)\n",
        "        data_time.update(time.time() - start)\n",
        "\n",
        "        # Move to default device\n",
        "        # images\n",
        "        images = images.to(device)  # (batch_size (N), 3, 300, 300)\n",
        "        boxes = [b.to(device) for b in boxes]\n",
        "        labels = [l.to(device) for l in labels]\n",
        "\n",
        "        # Forward prop.\n",
        "        # 여기서 model.py의 forward 함수의 인자로 넣어줄 images 가 전달된다.\n",
        "        predicted_locs, predicted_scores = model(images)  # (N, 8732, 4), (N, 8732, n_classes)\n",
        "\n",
        "        # Loss\n",
        "\n",
        "        loss = criterion(predicted_locs, predicted_scores, boxes, labels)  # scalar\n",
        "\n",
        "        # Backward prop.\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip gradients, if necessary\n",
        "        if grad_clip is not None:\n",
        "            clip_gradient(optimizer, grad_clip)\n",
        "\n",
        "        # Update model\n",
        "        optimizer.step()\n",
        "\n",
        "        losses.update(loss.item(), images.size(0))\n",
        "        batch_time.update(time.time() - start)\n",
        "\n",
        "        start = time.time()\n",
        "\n",
        "        # Print status\n",
        "        if i % print_freq == 0:\n",
        "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
        "                  'Batch Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "                  'Data Time {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
        "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(epoch, i, len(train_loader),\n",
        "                                                                  batch_time=batch_time,\n",
        "                                                                  data_time=data_time, loss=losses))\n",
        "    del predicted_locs, predicted_scores, images, boxes, labels  # free some memory since their histories may be stored\n",
        "\n"
      ],
      "metadata": {
        "id": "Iq4zIm572lK9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if checkpoint is None:\n",
        "    start_epoch = 0\n",
        "    model = SSD300(n_classes=11)\n",
        "    biases = list()\n",
        "    not_biases = list()\n",
        "    for param_name, param in model.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            if param_name.endswith('.bias'):\n",
        "                biases.append(param)\n",
        "            else:\n",
        "                not_biases.append(param)\n",
        "    optimizer = torch.optim.SGD(params=[{'params': biases, 'lr': 2 * lr}, {'params': not_biases}],\n",
        "                                lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
        "\n",
        "else:\n",
        "    checkpoint = torch.load(checkpoint)\n",
        "    start_epoch = checkpoint['epoch'] + 1\n",
        "    print('\\nLoaded checkpoint from epoch %d.\\n' % start_epoch)\n",
        "    model = checkpoint['model']\n",
        "    optimizer = checkpoint['optimizer']"
      ],
      "metadata": {
        "id": "Pb0FetCh2lNP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1cbdbb2-9429-4ff2-e502-426b06cce690"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Move to default device\n",
        "model = model.to(device)\n",
        "\n",
        "# loss 함수 지정\n",
        "criterion = MultiBoxLoss(priors_cxcy=model.priors_cxcy).to(device)\n",
        "\n",
        "# Custom dataloaders\n",
        "train_dataset = CustomDataset(data_folder, split='training')\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
        "                                           collate_fn=train_dataset.collate_fn,\n",
        "                                           pin_memory=True)  # note that we're passing the collate function here\n"
      ],
      "metadata": {
        "id": "BJYb_NPd7cr5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# epochs = iterations // (len(train_dataset) // 32)\n",
        "epochs = 10\n",
        "# decay_lr_at = [it // (len(train_dataset) // 32) for it in decay_lr_at]\n",
        "decay_lr_at = [8,9]\n",
        "print(epochs)\n",
        "print(decay_lr_at)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXBgsIIf75MF",
        "outputId": "399f7b27-df74-48c9-a9fc-af84cc33351f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "[8, 9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Epochs\n",
        "for epoch in range(start_epoch, epochs):\n",
        "    # Decay learning rate at particular epochs\n",
        "    if epoch in decay_lr_at:\n",
        "        adjust_learning_rate(optimizer, decay_lr_to)\n",
        "\n",
        "    # One epoch's training, train 함수로 학습 진행\n",
        "    train(train_loader=train_loader, model=model, criterion=criterion,\n",
        "          optimizer=optimizer,\n",
        "          epoch=epoch)\n",
        "    # Save checkpoint\n",
        "    save_checkpoint(epoch, model, optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-a8-mnL8A3o",
        "outputId": "b03b6461-fdad-4894-f3c3-b34f3f27b884"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0][0/200]\tBatch Time 9.726 (9.726)\tData Time 1.045 (1.045)\tLoss 22.1520 (22.1520)\t\n",
            "Epoch: [0][100/200]\tBatch Time 2.458 (3.181)\tData Time 2.237 (2.865)\tLoss 36.8416 (22.1324)\t\n",
            "Epoch: [1][0/200]\tBatch Time 1.337 (1.337)\tData Time 1.173 (1.173)\tLoss 19.7111 (19.7111)\t\n",
            "Epoch: [1][100/200]\tBatch Time 2.127 (2.129)\tData Time 1.888 (1.932)\tLoss 23.7204 (33.0984)\t\n",
            "Epoch: [2][0/200]\tBatch Time 2.297 (2.297)\tData Time 2.062 (2.062)\tLoss 33.6972 (33.6972)\t\n",
            "Epoch: [2][100/200]\tBatch Time 2.096 (2.138)\tData Time 1.877 (1.937)\tLoss 20.9102 (31.1142)\t\n",
            "Epoch: [3][0/200]\tBatch Time 1.523 (1.523)\tData Time 1.295 (1.295)\tLoss 34.2077 (34.2077)\t\n",
            "Epoch: [3][100/200]\tBatch Time 1.489 (2.130)\tData Time 1.336 (1.932)\tLoss 22.7399 (33.8085)\t\n",
            "Epoch: [4][0/200]\tBatch Time 2.155 (2.155)\tData Time 1.915 (1.915)\tLoss 27.3457 (27.3457)\t\n",
            "Epoch: [4][100/200]\tBatch Time 1.660 (2.065)\tData Time 1.502 (1.871)\tLoss 17.4686 (20.3029)\t\n",
            "Epoch: [5][0/200]\tBatch Time 1.032 (1.032)\tData Time 0.877 (0.877)\tLoss 16.5404 (16.5404)\t\n",
            "Epoch: [5][100/200]\tBatch Time 2.614 (1.941)\tData Time 2.369 (1.754)\tLoss 9.5519 (13.2837)\t\n",
            "Epoch: [6][0/200]\tBatch Time 1.548 (1.548)\tData Time 1.392 (1.392)\tLoss 12.2704 (12.2704)\t\n",
            "Epoch: [6][100/200]\tBatch Time 4.342 (2.065)\tData Time 4.122 (1.875)\tLoss 11.6752 (10.3842)\t\n",
            "Epoch: [7][0/200]\tBatch Time 3.806 (3.806)\tData Time 3.549 (3.549)\tLoss 15.1380 (15.1380)\t\n",
            "Epoch: [7][100/200]\tBatch Time 1.059 (2.126)\tData Time 0.909 (1.927)\tLoss 8.6057 (10.6473)\t\n",
            "DECAYING learning rate.\n",
            " The new LR is 0.000100\n",
            "\n",
            "Epoch: [8][0/200]\tBatch Time 2.539 (2.539)\tData Time 2.318 (2.318)\tLoss 9.0184 (9.0184)\t\n",
            "Epoch: [8][100/200]\tBatch Time 1.740 (2.020)\tData Time 1.587 (1.828)\tLoss 5.1777 (6.4211)\t\n",
            "DECAYING learning rate.\n",
            " The new LR is 0.000010\n",
            "\n",
            "Epoch: [9][0/200]\tBatch Time 1.065 (1.065)\tData Time 0.912 (0.912)\tLoss 5.1377 (5.1377)\t\n",
            "Epoch: [9][100/200]\tBatch Time 2.984 (2.107)\tData Time 2.759 (1.907)\tLoss 5.6220 (5.7276)\t\n"
          ]
        }
      ]
    }
  ]
}